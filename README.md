# ðŸ©º Medical AI Assistant: The Impact of Data Engineering on RAG Performance

## ðŸ“– Project Overview
This project involves building a specialized **Medical AI Doctor** capable of answering complex queries about cancer (Breast, Lung, Leukemia, etc.) with clinical precision.

The core objective was **scientific validation** of the hypothesis: **"Data Quality > Model Complexity."** To prove this, we developed a complete end-to-end pipelineâ€”from web scraping to fine-tuning a Large Language Model (LLM)â€”and ran a controlled experiment comparing a **Raw Data RAG System** vs. a **Clean Data RAG System**.

## ðŸš€ Key Features
* **Automated Web Scraping:** A robust pipeline to harvest medical articles directly from the *National Cancer Institute (cancer.gov)*.
* **Advanced Data Preprocessing (The "Secret Sauce"):**
    * **Smart Imputation:** Used **BioGPT** to generate medically accurate summaries for missing data points.
    * **Semantic Outlier Detection:** Implemented **Isolation Forest** algorithms to identify and remove non-medical "junk" text.
    * **Metadata Injection:** Injected Topic/Category tags directly into text chunks to drastically improve retrieval precision.
* **Fine-Tuned "Doctor" Model:** Trained a **Mistral 7B** model using **QLoRA** adapters to adopt a professional medical persona.
* **Dual RAG Architecture:** Built two parallel Retrieval-Augmented Generation systems (Raw vs. Clean) to conduct an A/B test on answer quality.

## ðŸ“‚ Datasets
1.  **Knowledge Base (Facts):**
    * **Source:** [National Cancer Institute (cancer.gov)](https://www.cancer.gov)
    * **Content:** Detailed protocols on symptoms, treatments, and diagnosis for major cancer types.
    * **Size:** ~300+ Verified Medical Articles.
2.  **Training Data (Reasoning):**
    * **Dataset:** `FreedomIntelligence/medical-o1-reasoning-SFT`
    * **Purpose:** Used to fine-tune the LLM to learn *how* to reason like a doctor (Clinical Chain-of-Thought).

## ðŸ› ï¸ Tech Stack
* **Language:** Python 3.10+
* **LLM Engineering:** [Unsloth](https://github.com/unslothai/unsloth) (Accelerated Training), Hugging Face Transformers, PEFT (QLoRA).
* **Model:** Mistral-7B-v0.3-bnb-4bit (Quantized).
* **Vector Search (RAG):** FAISS (Facebook AI Similarity Search), Sentence-BERT (`all-MiniLM-L6-v2`) for embeddings.
* **Data Science:** Pandas, NumPy, Scikit-learn (Isolation Forest), Matplotlib/Seaborn (EDA).
* **ETL Pipeline:** BeautifulSoup4, Requests.

## ðŸ“Š Project Pipeline
1.  **Data Acquisition:** Scraped raw HTML content from cancer.gov.
2.  **EDA (Exploratory Data Analysis):** Analyzed word counts, complexity, and clusters (Histograms, Boxplots, Pairplots).
3.  **Preprocessing:**
    * Normalized text.
    * Removed noise via Isolation Forest.
    * Imputed gaps using BioGPT.
4.  **Model Training:** Fine-tuned Mistral 7B for 60-600 steps on medical reasoning data.
5.  **RAG Implementation:** Indexed both "Raw" and "Clean" datasets into vector databases.
6.  **Evaluation:** Conducted A/B testing with identical medical queries.

## ðŸ† Results & Impact Analysis

The project successfully demonstrated the **"Garbage In, Garbage Out"** principle in Generative AI. We found that advanced preprocessing is critical for safety in medical applications.

### 1. ðŸš€ The "High Impact" Metric: Retrieval Safety
We measured **Context Purity**â€”the percentage of retrieved text that was actually relevant to the specific cancer type requested.

| Metric | System A (Raw Data) | System B (Clean Data) | **IMPACT** |
| :--- | :--- | :--- | :--- |
| **Retrieval Purity** | 33% (High Noise) | **100% (Pure)** | **âœ… 3x Reliability Boost** |
| **Cross-Contamination** | High (Mixed Cancer Types) | **Zero** | **ðŸ›¡ï¸ Risk Eliminated** |

> **Real-World Consequence:** When asked about *Breast Cancer*, the Raw System retrieved information about *Ovarian Cancer* (dangerous noise). The Clean System retrieved **only** Breast Cancer protocols, proving that our preprocessing pipeline eliminates life-critical hallucinations.

### 2. ðŸ“Š Quantitative NLP Metrics
Standard mathematical evaluation confirmed the qualitative improvements.

| Metric | System A (Raw) | System B (Clean) | Improvement | Meaning |
| :--- | :--- | :--- | :--- | :--- |
| **Factuality (ROUGE-L)** | 0.145 | **0.173** | **+19.3%** | The Clean model used ~20% more correct medical terminology. |
| **Depth (Word Count)** | 39 words | **49 words** | **+25.6%** | The Clean model provided more detailed and comprehensive answers. |

### ðŸ’¡ Conclusion
While standard RAG systems can answer questions, they are prone to dangerous retrieval errors when built on raw data. Our **Clean Data Pipeline** eliminated retrieval hallucinations and significantly improved factual accuracy, proving that **Data Engineering is the most critical factor in building safe Medical AI.**

---
*Created by [Your Name/Group Name]*
